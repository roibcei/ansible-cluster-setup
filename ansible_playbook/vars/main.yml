#replace x.x.x. to your ip's

base_license: XXXXXXXXXXXXXXXX #Optional since ontap 9.2+
cluster: BuciCluster
hostname: "x.x.x.242"
netmask: "255.255.255.0"
username: "admin"
password: "netapp123"
https_global: "true"
validate_certs_global: "false"
mgmt_home_port: e0c

hosts:
  node1:
    name: "Buciclustern1"
    ip: "x.x.x.243"
    subnet: "255.255.255.0"
    aggregate:
       name: "n1_data"
       diskcount: "10"
       raidsize: "28"
  node2:
    name: "Buciclustern2"
    ip: "x.x.x.244"
    cluster:
       private_ip: 169.254.10.11   #DO NOT CHANGE
       netmask: 255.255.0.0        #DO NOT CHANGE
    subnet: "255.255.255.0"

licenses:
  - XXXXXXXXXXXXXXXXXXXXXXXXXXXX #Enter licene code for protocol in here
  - XXXXXXXXXXXXXXXXXXXXXXXXXXXX

motd: "Welcome to XXXXX Storage System. This is a monitored system! "

dns:
  - { dns_domains: domain.local, dns_nameservers: "x.x.x.17,x.x.x.18", vserver: "{{ cluster }}"}
  - { dns_domains: domain.local, dns_nameservers: "x.x.x.17,x.x.x.18", vserver: SVM_Beci}
  - { dns_domains: domain.local, dns_nameservers: x.x.x.17, vserver: SVM_David}

ntp:
  - { server_name: domain.local, version: auto }

snmp:
  - { community_name: ansible_snmp, access_control: ro }

ports:
  - { node: "{{hosts['node1'].name }}", port: e0c, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{hosts['node1'].name }}", port: e0d, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{hosts['node1'].name }}", port: e0e, mtu: 1500 , flowcontrol: none, autonegotiate: true}
  - { node: "{{hosts['node1'].name }}", port: e0f, mtu: 1500 , flowcontrol: none, autonegotiate: true}
  - { node: "{{hosts['node2'].name }}", port: e0c, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{hosts['node2'].name }}", port: e0d, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{hosts['node2'].name }}", port: e0e, mtu: 1500 , flowcontrol: none, autonegotiate: true}
  - { node: "{{hosts['node2'].name }}", port: e0f, mtu: 1500 , flowcontrol: none, autonegotiate: true}

loginUsers:
  - { username: "test1", password: "8LetterLength", apps: "http,console", role: "readonly", vserver: "BuciCluster" }

ifgrps:
  - { name: a0a, node: "{{hosts['node1'].name }}", ports: "e0c,e0e", mode: multimode_lacp, mtu: 9000, distribution_function: ip }
  - { name: a0a, node: "{{hosts['node2'].name }}", ports: "e0c,e0e", mode: multimode_lacp, mtu: 9000, distribution_function: ip }
  - { name: a0b, node: "{{hosts['node1'].name }}", ports: "e0d,e0f", mode: multimode_lacp, mtu: 1500, distribution_function: ip }
  - { name: a0b, node: "{{hosts['node2'].name }}", ports: "e0d,e0f", mode: multimode_lacp, mtu: 1500, distribution_function: ip }


vlans:
  - { vlanid: 300, node: "{{hosts['node1'].name }}", phy_interface: "a0a" }
  - { vlanid: 400, node: "{{hosts['node1'].name }}", phy_interface: "a0a" }
  - { vlanid: 62, node: "{{hosts['node1'].name }}", phy_interface: "a0a" }
  - { vlanid: 300, node: "{{hosts['node2'].name }}", phy_interface: "a0a" }
  - { vlanid: 400, node: "{{hosts['node2'].name }}", phy_interface: "a0a" }
  - { vlanid: 62, node: "{{hosts['node2'].name }}", phy_interface: "a0a" }

bcasts:
  - { name: vlan_400, ports: "{{hosts['node1'].name }}:a0a-400,{{hosts['node2'].name }}:a0a-400", mtu: 1500 }
  - { name: vlan_300, ports: "{{hosts['node1'].name }}:a0a-300,{{hosts['node2'].name }}:a0a-300", mtu: 1500 }
  - { name: BD-Mgmt, ports: "{{hosts['node1'].name }}:e0c,{{hosts['node2'].name }}:e0c", mtu: 1500 }

bcastRename:
  old_name: "Default"
  new_name: "BD-Mgmt"

bcastsMTU:
  - { name: BD-Mgmt, mtu: 1500 }
  - { name: vlan_400, mtu: 9000 }

vservers:
  - { name: SVM_Beci, root_volume_aggregate: "{{ hosts['node1'].aggregate.name }}" , root_volume_security_style: unix }
  - { name: SVM_David, root_volume_aggregate: "{{ hosts['node1'].aggregate.name }}" , root_volume_security_style: unix }

lifs:
  - { name: lif1, node: "{{ hosts['node1'].name }}", port: a0a-400, address: 1.1.1.1, netmask: 255.255.255.0, vserver: SVM_Beci, role: data, protocols: cifs,nfs }
  - { name: lif2, node: "{{ hosts['node2'].name }}", port: a0a-300, address: 1.1.2.2, netmask: 255.255.255.0, vserver: SVM_Beci, role: data, protocols: cifs,nfs }
  - { name: lif1, node: "{{ hosts['node2'].name }}", port: a0a-300, address: 1.3.2.2, netmask: 255.255.255.0, vserver: SVM_David, role: data, protocols: cifs,nfs }

gateway: #if a different default route/gateway then the clusters default needs to be added
  - { vserver: SVM_Beci, destination: 0.0.0.0/0, gateway: x.x.x.1 }
  - { vserver: SVM_David, destination: 0.0.0.0/0, gateway: x.x.x.1 }

cifsad: # Vservers to join to an AD Domain
#  - { vserver: SVM_Beci, cifs_server_name: svm_beci, domain: "DOMAIN", admin_user: "USER",admin_password: "PASS", force: true } # Example 1 - Active Directory

cifsworkgroup: # Vservers to join to a local workgroup
  - { vserver: SVM_David, cifs_server_name: cifs-workgroup, workgroup: workgroup, force: true }
  - { vserver: SVM_Beci, cifs_server_name: cifs-workgroup2, workgroup: workgroup, force: true }


nfs: # Vservers to configure for NFS
  - { vserver: SVM_Beci, nfsv3: enabled, nfsv4: disabled, nfsv41: enabled, vstorage: enabled }
  - { vserver: SVM_David, nfsv3: enabled, nfsv4: disabled, nfsv41: enabled, vstorage: enabled }

exportrules:
  - { name: EP1, client_match: 0.0.0.0/0, vserver: SVM_Beci }
  - { name: EP1, client_match: 1.1.1.0/24, vserver: SVM_Beci }
  - { name: EP1, client_match: 0.0.0.0/0, vserver: SVM_David }
  - { name: EP2, client_match: 1.1.1.0/24, vserver: SVM_David }

volumes:
  - { name: vol1, aggr: "{{ hosts['node1'].aggregate.name }}", size: 10, policy: EP1, snappercent: 3, vserver: SVM_Beci, securitystyle: unix  }
  - { name: vol2, aggr: "{{ hosts['node1'].aggregate.name }}", size: 10, policy: EP1, snappercent: 3, vserver: SVM_Beci, securitystyle: unix  }
  - { name: vol3, aggr: "{{ hosts['node1'].aggregate.name }}", size: 10, policy: EP2, snappercent: 3, vserver: SVM_David, securitystyle: unix  }
  - { name: vol4, aggr: "{{ hosts['node1'].aggregate.name }}", size: 10, policy: EP1, snappercent: 3, vserver: SVM_David, securitystyle: unix  }

sp:
  - { node: "{{ hosts['node1'].name }}", dhcp: none, ip_enabled: true, address_type: ipv4, state: present, ip_address: x.x.x.240, netmask: 255.255.255.0, gateway: x.x.x.1 }
  - { node: "{{ hosts['node2'].name }}", dhcp: none, ip_enabled: true, address_type: ipv4, state: present, ip_address: x.x.x.241, netmask: 255.255.255.0, gateway: x.x.x.1 }

cifsAcl:
  - { share_name: vol1, vserver: SVM_David, user: test, permission: full_control } # not availible this version..
  - { share_name: vol1, vserver: SVM_David, user: Everyone, permission: read } # not availible this version..

cifsShares:
  - { share_name: share1, vol_path: "/vol1", vserver: SVM_Beci, share_properties: "browsable,oplocks", symlink_properties: "enable" }
  - { share_name: share2, vol_path: "/vol2", vserver: SVM_Beci, share_properties: "browsable,oplocks", symlink_properties: "enable" }
  - { share_name: share3, vol_path: "/vol3", vserver: SVM_David, share_properties: "browsable,oplocks", symlink_properties: "enable" }
  - { share_name: share4 ,vol_path: "/vol4", vserver: SVM_David, share_properties: "browsable,oplocks", symlink_properties: "enable" }
